pi@raspberrypi:~/assignent-8/f25-csc4200-coderoom-assignment8-llm-prompts-Assignment8-LLM-Prompts-Wei-Wang-sGroup $ pip install -U transformers
Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple
Requirement already satisfied: transformers in /home/pi/.local/lib/python3.9/site-packages (4.57.1)
Collecting transformers
  Using cached https://www.piwheels.org/simple/transformers/transformers-4.57.1-py3-none-any.whl (12.0 MB)
  Downloading https://www.piwheels.org/simple/transformers/transformers-4.56.2-py3-none-any.whl (11.6 MB)
     |████████████████████████████████| 11.6 MB 6.1 MB/s 
Requirement already satisfied: filelock in /home/pi/.local/lib/python3.9/site-packages (from transformers) (3.19.1)
Requirement already satisfied: regex!=2019.12.17 in /home/pi/.local/lib/python3.9/site-packages (from transformers) (2025.11.3)
Requirement already satisfied: pyyaml>=5.1 in /home/pi/.local/lib/python3.9/site-packages (from transformers) (6.0.3)
Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/pi/.local/lib/python3.9/site-packages (from transformers) (0.36.0)
Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/pi/.local/lib/python3.9/site-packages (from transformers) (0.22.1)
Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from transformers) (1.19.5)
Requirement already satisfied: packaging>=20.0 in /home/pi/.local/lib/python3.9/site-packages (from transformers) (25.0)
Requirement already satisfied: tqdm>=4.27 in /home/pi/.local/lib/python3.9/site-packages (from transformers) (4.67.1)
Requirement already satisfied: safetensors>=0.4.3 in /home/pi/.local/lib/python3.9/site-packages (from transformers) (0.7.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/pi/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/pi/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)
Requirement already satisfied: fsspec>=2023.5.0 in /home/pi/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)
pi@raspberrypi:~/assignent-8/f25-csc4200-coderoom-assignment8-llm-prompts-Assignment8-LLM-Prompts-Wei-Wang-sGroup $ python3 prompt_node.py Pi-1
[INIT] Node Pi-1 ready at 10.143.213.165:5000
[INIT] Broadcast address: 10.143.255.255
[START] Listener thread started
[START] Broadcaster thread started
[SYNC] Broadcasting: [PEER_SYNC]|Pi-1|1|1763949277921|0|3|10.143.213.165,5000|77370747
[START] Heartbeat thread started
[START] Summary thread started
[START] Node Pi-1 running
[INFO] Discovery: 5s, Ping: 15s, Timeout: 30s

[PONG] Sent to james
Traceback (most recent call last):
  File "/home/pi/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 741, in getattribute_from_module
    return getattribute_from_module(transformers_module, attr)
  File "/home/pi/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 745, in getattribute_from_module
    raise ValueError(f"Could not find {attr} in {transformers_module}!")
ValueError: Could not find GPT2LMHeadModel in <module 'transformers' from '/home/pi/.local/lib/python3.9/site-packages/transformers/__init__.py'>!

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/assignent-8/f25-csc4200-coderoom-assignment8-llm-prompts-Assignment8-LLM-Prompts-Wei-Wang-sGroup/prompt_node.py", line 175, in <module>
    main(node_id, debug)
  File "/home/pi/assignent-8/f25-csc4200-coderoom-assignment8-llm-prompts-Assignment8-LLM-Prompts-Wei-Wang-sGroup/prompt_node.py", line 120, in main
    model, tok = load_model()
  File "/home/pi/assignent-8/f25-csc4200-coderoom-assignment8-llm-prompts-Assignment8-LLM-Prompts-Wei-Wang-sGroup/prompt_node.py", line 29, in load_model
    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)
  File "/home/pi/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 601, in from_pretrained
    model_class = _get_model_class(config, cls._model_mapping)
  File "/home/pi/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 394, in _get_model_class
    supported_models = model_mapping[type(config)]
  File "/home/pi/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 807, in __getitem__
    return self._load_attr_from_module(model_type, model_name)
  File "/home/pi/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 821, in _load_attr_from_module
    return getattribute_from_module(self._modules[module_name], attr)
  File "/home/pi/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 743, in getattribute_from_module
    raise ValueError(f"Could not find {attr} neither in {module} nor in {transformers_module}!")
ValueError: Could not find GPT2LMHeadModel neither in <module 'transformers.models.gpt2' from '/home/pi/.local/lib/python3.9/site-packages/transformers/models/gpt2/__init__.py'> nor in <module 'transformers' from '/home/pi/.local/lib/python3.9/site-packages/transformers/__init__.py'>!
pi@raspberrypi:~/assignent-8/f25-csc4200-coderoom-assignment8-llm-prompts-Assignment8-LLM-Prompts-Wei-Wang-sGroup $ 



python3 -c "from transformers import GPT2LMHeadModel; print('GPT2 model class found ✓')"

pi@raspberrypi:~/assignent-8/f25-csc4200-coderoom-assignment8-llm-prompts-Assignment8-LLM-Prompts-Wei-Wang-sGroup $ python3 -c "from transformers import GPT2LMHeadModel; print('GPT2 model class found ✓')"
Traceback (most recent call last):
  File "<string>", line 1, in <module>
ImportError: cannot import name 'GPT2LMHeadModel' from 'transformers' (/home/pi/.local/lib/python3.9/site-packages/transformers/__init__.py)
